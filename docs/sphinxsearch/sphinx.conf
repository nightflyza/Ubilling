#
# Sphinx configuration file sample
#
# WARNING! While this sample file mentions all available options,
# it contains (very) short helper descriptions only. Please refer to
# doc/sphinx.html for details.
#

#############################################################################
## data source definition
#############################################################################

source src1
{
	type			= mysql
	sql_host		= 127.0.0.1
	sql_user		= root
	sql_pass		= rootpassword
	sql_db			= stg
	sql_port		= 3306	# optional, default is 3306
	sql_query_pre		= SET NAMES utf8
        sql_query               = \
                SELECT `nethosts`.`id`, 'ip' AS `title`,  `nethosts`.`ip` as value, `users`.`login` \
                FROM `nethosts` RIGHT JOIN `users` ON `nethosts`.`ip` = `users`.`ip` 

	sql_attr_string		= login
	sql_attr_string		= title
        sql_field_string        = value
	sql_ranged_throttle	= 0
}
source src2 : src1
{       
        sql_query               = \
		SELECT `nethosts`.`id`, 'realname' AS `title`, `users`.`login`, `realname`.`realname` as value \
		FROM `nethosts` RIGHT JOIN `users` ON `nethosts`.`ip` = `users`.`ip` JOIN `realname` ON `realname`.`login` = `users`.`login`
        
	sql_attr_string		= login
	sql_attr_string		= title
        sql_field_string        = value
}
source src3 : src1
{       
        sql_query               = \
                SELECT `nethosts`.`id`, 'mac' AS `title`, `nethosts`.`mac` AS `value`, `users`.`login` \
                FROM `nethosts` RIGHT JOIN `users` ON `nethosts`.`ip` = `users`.`ip`
 
	sql_attr_string		= login
	sql_attr_string		= title
        sql_field_string        = value
}
source src4 : src1
{
	sql_query		= \
		SELECT `nethosts`.`id`, 'login' AS `title`, `users`.`login` AS `value`, `users`.`login` AS `login` \
		FROM `nethosts` RIGHT JOIN `users` ON `nethosts`.`ip` = `users`.`ip`

	sql_attr_string		= login
	sql_attr_string		= title
	sql_field_string	= value
}
source src5 : src1
{
	sql_query		= \
		SELECT nethosts.id, 'address' AS `title`, `users`.`login`,concat(`cityname`, ' ', `streetname`, ' ', `buildnum`, IF(`apt`, concat('/',`apt`), '')) AS `value` \
		FROM `users` LEFT JOIN `nethosts` USING (`ip`) \
		LEFT JOIN `address` ON (`users`.`login`=`address`.`login`) \
		LEFT JOIN `apt` ON (`address`.`aptid`=`apt`.`id`) \
		LEFT JOIN `build` ON (`apt`.`buildid`=`build`.`id`) \
		LEFT JOIN `street` ON (`build`.`streetid`=`street`.`id`) \
		LEFT JOIN `city` ON (`street`.`cityid`=`city`.`id`) 

	sql_attr_string		= login
	sql_attr_string		= title
	sql_field_string	= value

}
source src6 : src1
{
	sql_query		= \
		SELECT `nethosts`.`id`, 'mobile' AS `title`, `users`.`login`, `phones`.`mobile` as `value` \
		FROM `nethosts` RIGHT JOIN `users` ON `nethosts`.`ip` = `users`.`ip` LEFT JOIN `phones` ON `users`.`login` = `phones`.`login` 

	sql_attr_string		= login
	sql_attr_string		= title
	sql_field_string	= value

}
source src7 : src1
{
	sql_query		= \
		SELECT `nethosts`.`id`, 'phone' AS `title`, `users`.`login`, `phones`.`phone` as `value` \
		FROM `nethosts` RIGHT JOIN `users` ON `nethosts`.`ip` = `users`.`ip` LEFT JOIN `phones` ON `users`.`login` = `phones`.`login`

	sql_attr_string		= login
	sql_attr_string		= title
	sql_field_string	= value

}
source src8 : src1
{
	sql_query		= \
		SELECT `nethosts`.`id`, 'contracts' AS `title`, `users`.`login`, `contracts`.`contract` as `value` \
		FROM `nethosts` RIGHT JOIN `users` ON `nethosts`.`ip` = `users`.`ip` LEFT JOIN `contracts` ON `users`.`login` = `contracts`.`login`

	sql_attr_string		= login
	sql_attr_string		= title
	sql_field_string	= value

}
source src9 : src1
{
	sql_query		= \
		SELECT `nethosts`.`id`, 'paymentid' AS `title`, `users`.`login`, `op_customers`.`virtualid` as `value` \
		FROM `nethosts` RIGHT JOIN `users` ON `nethosts`.`ip` = `users`.`ip` LEFT JOIN `op_customers` ON `users`.`login` = `op_customers`.`realid`
	
	sql_attr_string		= login
	sql_attr_string		= title
	sql_field_string	= value

}
# inherited source example
#
# all the parameters are copied from the parent source,
# and may then be overridden in this source definition
source src1throttled : src1
{
	sql_ranged_throttle	= 100
}

#############################################################################
## index definition
#############################################################################

# local index example
#
# this is an index which is stored locally in the filesystem
#
# all indexing-time options (such as morphology and charsets)
# are configured per local index
index ip
{
	source			= src1
	path			= /opt/sphinx/sphinxdata/ip
	mlock			= 0
	morphology		= none
	min_word_len		= 1
	min_prefix_len		= 2
#	min_infix_len		= 2
	expand_keywords		= 1
#	index_exact_words	= 1
	html_strip		= 0
	blend_mode		= trim_both, skip_pure
#				  +     -       :      .       ,      '      `
#				                              U+0020
	blend_chars		= U+002B,U+002D,U+003A,U+002E,U+002C,U+0027,U+0060
}
index mac : ip
{
	source			= src3
	path			= /opt/sphinx/sphinxdata/mac
}
index realname : ip
{
	source			= src2
        path                    = /opt/sphinx/sphinxdata/realname
}
index login : ip
{
	source			= src4
	path			= /opt/sphinx/sphinxdata/login
}
index fulladdress : ip
{
	source			= src5
	path			= /opt/sphinx/sphinxdata/fulladdres
}
index mobile : ip
{
	source			= src6
	path			= /opt/sphinx/sphinxdata/mobile
	min_infix_len		= 2
}
index phone : ip
{
	source			= src7
	path			= /opt/sphinx/sphinxdata/phone
}
index contract : ip
{
	source			= src8
	path			= /opt/sphinx/sphinxdata/contract
}
index paymentid : ip
{
	source			= src9
	path			= /opt/sphinx/sphinxdata/paymentid
}
# inherited index example
#
# all the parameters are copied from the parent index,
# and may then be overridden in this index definition
#index test1stemmed : test1
#{
#	path			= /var/data/test1stemmed
#	morphology		= stem_en
#}


# distributed index example
#
# this is a virtual index which can NOT be directly indexed,
# and only contains references to other local and/or remote indexes
#index dist1
#{
	# 'distributed' index type MUST be specified
#	type			= distributed

	# local index to be searched
	# there can be many local indexes configured
#	local			= test1
#	local			= test1stemmed

	# remote agent
	# multiple remote agents may be specified
	# syntax for TCP connections is 'hostname:port:index1,[index2[,...]]'
	# syntax for local UNIX connections is '/path/to/socket:index1,[index2[,...]]'
#	agent			= localhost:9313:remote1
#	agent			= localhost:9314:remote2,remote3
	# agent			= /var/run/searchd.sock:remote4

	# remote agent mirrors groups, aka mirrors, aka HA agents
	# defines 2 or more interchangeable mirrors for a given index part
	#
	# agent			= server3:9312 | server4:9312 :indexchunk2
	# agent			= server3:9312:chunk2server3 | server4:9312:chunk2server4
	# agent			= server3:chunk2server3 | server4:chunk2server4
	# agent			= server21|server22|server23:chunk2


	# blackhole remote agent, for debugging/testing
	# network errors and search results will be ignored
	#
	# agent_blackhole		= testbox:9312:testindex1,testindex2


	# persistenly connected remote agent
	# reduces connect() pressure, requires that workers IS threads
	#
	# agent_persistent		= testbox:9312:testindex1,testindex2


	# remote agent connection timeout, milliseconds
	# optional, default is 1000 ms, ie. 1 sec
#	agent_connect_timeout	= 1000

	# remote agent query timeout, milliseconds
	# optional, default is 3000 ms, ie. 3 sec
#	agent_query_timeout		= 3000

	# HA mirror agent strategy
	# optional, defaults to ??? (random mirror)
	# know values are nodeads, noerrors, roundrobin, nodeadstm, noerrorstm
	#
	# ha_strategy				= nodeads

	# path to RLP context file
	# optional, defaut is empty
	#
	# rlp_context = /usr/local/share/sphinx/rlp/rlp-context.xml
#}


# realtime index example
#
# you can run INSERT, REPLACE, and DELETE on this index on the fly
# using MySQL protocol (see 'listen' directive below)
#index rt
#{
	# 'rt' index type must be specified to use RT index
#	type			= rt

	# index files path and file name, without extension
	# mandatory, path must be writable, extensions will be auto-appended
#	path			= /var/data/rt

	# RAM chunk size limit
	# RT index will keep at most this much data in RAM, then flush to disk
	# optional, default is 128M
	#
	# rt_mem_limit		= 512M

	# full-text field declaration
	# multi-value, mandatory
#	rt_field		= title
#	rt_field		= content

	# unsigned integer attribute declaration
	# multi-value (an arbitrary number of attributes is allowed), optional
	# declares an unsigned 32-bit attribute
#	rt_attr_uint		= gid

	# RT indexes currently support the following attribute types:
	# uint, bigint, float, timestamp, string, mva, mva64, json
	#
	# rt_attr_bigint		= guid
	# rt_attr_float		= gpa
	# rt_attr_timestamp	= ts_added
	# rt_attr_string		= author
	# rt_attr_multi		= tags
	# rt_attr_multi_64	= tags64
	# rt_attr_json		= extra_data
#}

#############################################################################
## indexer settings
#############################################################################

indexer
{
	# memory limit, in bytes, kiloytes (16384K) or megabytes (256M)
	# optional, default is 128M, max is 2047M, recommended is 256M to 1024M
	mem_limit		= 128M

	# maximum IO calls per second (for I/O throttling)
	# optional, default is 0 (unlimited)
	#
	# max_iops		= 40


	# maximum IO call size, bytes (for I/O throttling)
	# optional, default is 0 (unlimited)
	#
	# max_iosize		= 1048576


	# maximum xmlpipe2 field length, bytes
	# optional, default is 2M
	#
	# max_xmlpipe2_field	= 4M


	# write buffer size, bytes
	# several (currently up to 4) buffers will be allocated
	# write buffers are allocated in addition to mem_limit
	# optional, default is 1M
	#
	# write_buffer		= 1M


	# maximum file field adaptive buffer size
	# optional, default is 8M, minimum is 1M
	#
	# max_file_field_buffer	= 32M


	# how to handle IO errors in file fields
	# known values are 'ignore_field', 'skip_document', and 'fail_index'
	# optional, default is 'ignore_field'
	#
	# on_file_field_error = skip_document


	# lemmatizer cache size
	# improves the indexing time when the lemmatization is enabled
	# optional, default is 256K
	#
	# lemmatizer_cache = 512M
}

#############################################################################
## searchd settings
#############################################################################

searchd
{
	# [hostname:]port[:protocol], or /unix/socket/path to listen on
	# known protocols are 'sphinx' (SphinxAPI) and 'mysql41' (SphinxQL)
	#
	# multi-value, multiple listen points are allowed
	# optional, defaults are 9312:sphinx and 9306:mysql41, as below
	#
	# listen			= 127.0.0.1
	# listen			= 192.168.0.1:9312
	# listen			= 9312
	# listen			= /var/run/searchd.sock
	listen			= 9312
	listen			= 9306:mysql41

	# log file, searchd run info is logged here
	# optional, default is 'searchd.log'
	log			= /opt/sphinx/sphinxdata/logs/searchd.log

	# query log file, all search queries are logged here
	# optional, default is empty (do not log queries)
	query_log		= /opt/sphinx/sphinxdata/logs/query.log

	# client read timeout, seconds
	# optional, default is 5
	read_timeout		= 5

	# request timeout, seconds
	# optional, default is 5 minutes
	client_timeout		= 300

	# maximum amount of children to fork (concurrent searches to run)
	# optional, default is 0 (unlimited)
	max_children		= 30

	# maximum amount of persistent connections from this master to each agent host
	# optional, but necessary if you use agent_persistent. It is reasonable to set the value
	# as max_children, or less on the agent's hosts.
	persistent_connections_limit	= 30

	# PID file, searchd process ID file name
	# mandatory
	pid_file		= /opt/sphinx/sphinxdata/searchd.pid

	# seamless rotate, prevents rotate stalls if precaching huge datasets
	# optional, default is 1
	seamless_rotate		= 1

	# whether to forcibly preopen all indexes on startup
	# optional, default is 1 (preopen everything)
	preopen_indexes		= 1

	# whether to unlink .old index copies on succesful rotation.
	# optional, default is 1 (do unlink)
	unlink_old		= 1

	# attribute updates periodic flush timeout, seconds
	# updates will be automatically dumped to disk this frequently
	# optional, default is 0 (disable periodic flush)
	#
	# attr_flush_period	= 900


	# MVA updates pool size
	# shared between all instances of searchd, disables attr flushes!
	# optional, default size is 1M
	#mva_updates_pool	= 1M

	# max allowed network packet size
	# limits both query packets from clients, and responses from agents
	# optional, default size is 8M
	max_packet_size		= 8M

	# max allowed per-query filter count
	# optional, default is 256
	max_filters		= 256

	# max allowed per-filter values count
	# optional, default is 4096
	max_filter_values	= 4096


	# socket listen queue length
	# optional, default is 5
	#
	# listen_backlog		= 5


	# per-keyword read buffer size
	# optional, default is 256K
	#
	# read_buffer		= 256K


	# unhinted read size (currently used when reading hits)
	# optional, default is 32K
	#
	# read_unhinted		= 32K


	# max allowed per-batch query count (aka multi-query count)
	# optional, default is 32
	max_batch_queries	= 32


	# max common subtree document cache size, per-query
	# optional, default is 0 (disable subtree optimization)
	#
	# subtree_docs_cache	= 4M


	# max common subtree hit cache size, per-query
	# optional, default is 0 (disable subtree optimization)
	#
	# subtree_hits_cache	= 8M


	# multi-processing mode (MPM)
	# known values are none, fork, prefork, and threads
	# threads is required for RT backend to work
	# optional, default is threads
	workers			= threads # for RT to work


	# max threads to create for searching local parts of a distributed index
	# optional, default is 0, which means disable multi-threaded searching
	# should work with all MPMs (ie. does NOT require workers=threads)
	#
	# dist_threads		= 4


	# binlog files path; use empty string to disable binlog
	# optional, default is build-time configured data directory
	#
	binlog_path		= # disable logging
	# binlog_path		= /var/data # binlog.001 etc will be created there


	# binlog flush/sync mode
	# 0 means flush and sync every second
	# 1 means flush and sync every transaction
	# 2 means flush every transaction, sync every second
	# optional, default is 2
	#
	# binlog_flush		= 2


	# binlog per-file size limit
	# optional, default is 128M, 0 means no limit
	#
	# binlog_max_log_size	= 256M


	# per-thread stack size, only affects workers=threads mode
	# optional, default is 64K
	#
	# thread_stack			= 128K


	# per-keyword expansion limit (for dict=keywords prefix searches)
	# optional, default is 0 (no limit)
	#
	# expansion_limit		= 1000


	# RT RAM chunks flush period
	# optional, default is 0 (no periodic flush)
	#
	# rt_flush_period		= 900


	# query log file format
	# optional, known values are plain and sphinxql, default is plain
	#
	# query_log_format		= sphinxql


	# version string returned to MySQL network protocol clients
	# optional, default is empty (use Sphinx version)
	#
	# mysql_version_string	= 5.0.37


	# default server-wide collation
	# optional, default is libc_ci
	#
	# collation_server		= utf8_general_ci


	# server-wide locale for libc based collations
	# optional, default is C
	#
	# collation_libc_locale	= ru_RU.UTF-8


	# threaded server watchdog (only used in workers=threads mode)
	# optional, values are 0 and 1, default is 1 (watchdog on)
	#
	# watchdog				= 1

	
	# costs for max_predicted_time model, in (imaginary) nanoseconds
	# optional, default is "doc=64, hit=48, skip=2048, match=64"
	#
	# predicted_time_costs	= doc=64, hit=48, skip=2048, match=64


	# current SphinxQL state (uservars etc) serialization path
	# optional, default is none (do not serialize SphinxQL state)
	#
	# sphinxql_state			= sphinxvars.sql


	# maximum RT merge thread IO calls per second, and per-call IO size
	# useful for throttling (the background) OPTIMIZE INDEX impact
	# optional, default is 0 (unlimited)
	#
	# rt_merge_iops			= 40
	# rt_merge_maxiosize		= 1M


	# interval between agent mirror pings, in milliseconds
	# 0 means disable pings
	# optional, default is 1000
	#
	# ha_ping_interval		= 0


	# agent mirror statistics window size, in seconds
	# stats older than the window size (karma) are retired
	# that is, they will not affect master choice of agents in any way
	# optional, default is 60 seconds
	#
	# ha_period_karma			= 60


	# delay between preforked children restarts on rotation, in milliseconds
	# optional, default is 0 (no delay)
	#
	# prefork_rotation_throttle	= 100


	# a prefix to prepend to the local file names when creating snippets
	# with load_files and/or load_files_scatter options
	# optional, default is empty
	#
	# snippets_file_prefix		= /mnt/common/server1/
}

#############################################################################
## common settings
#############################################################################

common
{

	# lemmatizer dictionaries base path
	# optional, defaut is /usr/local/share (see ./configure --datadir)
	#
	# lemmatizer_base = /usr/local/share/sphinx/dicts


	# how to handle syntax errors in JSON attributes
	# known values are 'ignore_attr' and 'fail_index'
	# optional, default is 'ignore_attr'
	#
	# on_json_attr_error = fail_index


	# whether to auto-convert numeric values from strings in JSON attributes
	# with auto-conversion, string value with actually numeric data
	# (as in {"key":"12345"}) gets stored as a number, rather than string
	# optional, allowed values are 0 and 1, default is 0 (do not convert)
	#
	# json_autoconv_numbers = 1


	# whether and how to auto-convert key names in JSON attributes
	# known value is 'lowercase'
	# optional, default is unspecified (do nothing)
	#
	# json_autoconv_keynames = lowercase


	# path to RLP root directory
	# optional, defaut is /usr/local/share (see ./configure --datadir)
	#
	# rlp_root = /usr/local/share/sphinx/rlp


	# path to RLP environment file
	# optional, defaut is /usr/local/share/rlp-environment.xml (see ./configure --datadir)
	#
	# rlp_environment = /usr/local/share/sphinx/rlp/rlp/etc/rlp-environment.xml


	# maximum total size of documents batched before processing them by the RLP
	# optional, default is 51200
	#
	# rlp_max_batch_size = 100k


	# maximum number of documents batched before processing them by the RLP
	# optional, default is 50
	#
	# rlp_max_batch_docs = 100


	# trusted plugin directory
	# optional, default is empty (disable UDFs)
	#
	# plugin_dir			= /usr/local/sphinx/lib

}

# --eof--
